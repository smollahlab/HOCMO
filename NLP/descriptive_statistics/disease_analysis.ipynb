{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e6e6b370",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "67aee946",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir = \"..\"\n",
    "\n",
    "# discard the \"text\" data and mark which journal each article originated from\n",
    "with open(f'{dir}/savedCellArticles.pkl', 'rb') as f:\n",
    "    cell_data = pickle.load(f) # 924 articles\n",
    "    filtered_cell_data = {article: [entities, 'cell'] for article, [text, entities] in cell_data.items()}\n",
    "\n",
    "with open(f'{dir}/savedNatureArticles.pkl', 'rb') as f:\n",
    "    nature_data = pickle.load(f) # 401 articles\n",
    "    filtered_nature_data = {article: [entities, 'nature'] for article, [text, entities] in nature_data.items()}\n",
    "\n",
    "raw_combined_data = filtered_cell_data | filtered_nature_data # 1325 articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "110f2743",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check that delimiter is not a word found as an entity\n",
    "delimiter = 'delim'\n",
    "for article, [entities, origin] in raw_combined_data.items():\n",
    "    if (entities['word'] == delimiter).any():\n",
    "        print('Match found.') # we don't want to see this\n",
    "\n",
    "# write all entities to a text file\n",
    "# delimiter is used because the UMLS Norm tool sometimes outputs more than one line of output per input word\n",
    "# so this is a crude way of marking which lines in the output correspond to which line in the input\n",
    "with open('NormInput.txt', 'w', encoding='utf-8') as f:\n",
    "    for article, [entities, origin] in raw_combined_data.items():\n",
    "        f.write(f'\\n{delimiter}\\n'.join(entities['word'].tolist()))\n",
    "        f.write(f'\\n{delimiter}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "87121484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# at this point, the norm tool should have been run externally on the files\n",
    "\n",
    "# read in the Norm tool output file, process each line of output\n",
    "normalized_words = []\n",
    "with open('NormOutput.txt', 'r', encoding='utf-8') as f:\n",
    "    cache = ''\n",
    "    while True:\n",
    "        line = f.readline().strip()\n",
    "        if not line:\n",
    "            break\n",
    "        if line == f'{delimiter}|{delimiter}':\n",
    "            normalized_words.append(cache)\n",
    "        else:\n",
    "            cache = line\n",
    "normalized_words = [word.split('|')[1] for word in normalized_words]\n",
    "\n",
    "# populate the \"normalized word\" column of the corresponding entities dataframe \n",
    "for article, [entities, origin] in raw_combined_data.items():\n",
    "    n = len(entities['word'])\n",
    "    normalized_words_subset = normalized_words[:n]\n",
    "    del normalized_words[:n]\n",
    "    entities['normalized word'] = normalized_words_subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "83c4682c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the frequency of each word\n",
    "disease_words = np.array([])\n",
    "unnormed_disease_words = np.array([])\n",
    "# word_lengths = np.array([])\n",
    "for article, [entities, origin] in raw_combined_data.items():\n",
    "    # aggregate every disease words instance\n",
    "    disease_words = np.append(disease_words, entities[entities['entity'] == 'disease']['normalized word'].astype('string').to_numpy())\n",
    "    unnormed_disease_words = np.append(unnormed_disease_words, entities[entities['entity'] == 'disease']['word'].astype('string').to_numpy())\n",
    "\n",
    "# calculate frequency of each distinct word\n",
    "uniq_disease_words, disease_counts = np.unique(disease_words, return_counts=True)\n",
    "uniq_unnormed_disease_words = np.unique(unnormed_disease_words)\n",
    "\n",
    "# sort by frequency\n",
    "disease_by_counts = {word: count for count, word in sorted(zip(disease_counts, uniq_disease_words), reverse=True)}\n",
    "disease_by_counts = pd.DataFrame({\n",
    "    'word': disease_by_counts.keys(),\n",
    "    'count': disease_by_counts.values()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7e8da368",
   "metadata": {},
   "outputs": [],
   "source": [
    "disease_by_counts.head(n=100).to_excel('most_frequent_diseases.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "1c410d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manual categorization for the first 100 entries\n",
    "\n",
    "# sort the general categories of diseases\n",
    "disease_categories = pd.read_excel('most_frequent_diseases.xlsx')\n",
    "categories_counts = {}\n",
    "disease_categories.fillna('', inplace=True)\n",
    "for index, row in disease_categories.iterrows():\n",
    "    if row['categorization'] == '':\n",
    "        continue\n",
    "    curr = categories_counts.get(row['categorization'], 0)\n",
    "    categories_counts[row['categorization']] = curr + int(row['count'])\n",
    "categories_by_counts = dict(sorted(categories_counts.items(), key=lambda item: item[1], reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "eac4ad1a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cancer': 502,\n",
       " 'breast cancer': 188,\n",
       " 'cardiovascular disease': 134,\n",
       " 'neurological disease': 115,\n",
       " 'blood cancer': 87,\n",
       " 'lung cancer': 56,\n",
       " 'prostate cancer': 56,\n",
       " 'brain cancer': 54,\n",
       " 'liver cancer': 49,\n",
       " 'mental health disorder': 42,\n",
       " 'stomach cancer': 37,\n",
       " 'colorectal cancer': 28,\n",
       " 'viral infection': 20,\n",
       " 'obesity': 15,\n",
       " 'pancreatic cancer': 13,\n",
       " 'skin cancer': 12,\n",
       " 'lymphatic cancer': 11,\n",
       " 'diabetes': 11,\n",
       " 'immunodeficiency syndrome': 11,\n",
       " 'ovarian cancer': 10,\n",
       " 'kidney cancer': 10,\n",
       " 'esophageal cancer': 7,\n",
       " 'adenocarcinoma': 7,\n",
       " 'neuroblastoma': 6,\n",
       " 'pulmonary disease': 6,\n",
       " 'arthritis': 6,\n",
       " 'nasopharyngeal cancer': 5}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories_by_counts\n",
    "# top 5 general categories:\n",
    "# 1) breast cancer\n",
    "# 2) cardiovascular disease\n",
    "# 3) neurological disease\n",
    "# 4) blood cancer\n",
    "# 5) lung cancer\n",
    "# \"cancer\" is by far the most abundant entity, but it is not \n",
    "# specific enough to be its own category. However, this suggests \n",
    "# that other types of cancer may deserve more weight than \n",
    "# cardiovascular or neurological disease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bcd22410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>word</th>\n",
       "      <th>count</th>\n",
       "      <th>categorization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>cancer</td>\n",
       "      <td>347</td>\n",
       "      <td>cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>tumor</td>\n",
       "      <td>137</td>\n",
       "      <td>cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>breast cancer</td>\n",
       "      <td>72</td>\n",
       "      <td>breast cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7 mcf</td>\n",
       "      <td>52</td>\n",
       "      <td>breast cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>hcc</td>\n",
       "      <td>39</td>\n",
       "      <td>liver cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>95</td>\n",
       "      <td>breast tumor</td>\n",
       "      <td>5</td>\n",
       "      <td>breast cancer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>atrt</td>\n",
       "      <td>5</td>\n",
       "      <td>neurological disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>97</td>\n",
       "      <td>atherosclerosis</td>\n",
       "      <td>5</td>\n",
       "      <td>cardiovascular disease</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>anxiety</td>\n",
       "      <td>5</td>\n",
       "      <td>mental health disorder</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>99</td>\n",
       "      <td>aids</td>\n",
       "      <td>5</td>\n",
       "      <td>immunodeficiency syndrome</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0             word  count             categorization\n",
       "0            0           cancer    347                     cancer\n",
       "1            1            tumor    137                     cancer\n",
       "2            2    breast cancer     72              breast cancer\n",
       "3            3            7 mcf     52              breast cancer\n",
       "4            4              hcc     39               liver cancer\n",
       "..         ...              ...    ...                        ...\n",
       "95          95     breast tumor      5              breast cancer\n",
       "96          96             atrt      5       neurological disease\n",
       "97          97  atherosclerosis      5     cardiovascular disease\n",
       "98          98          anxiety      5     mental health disorder\n",
       "99          99             aids      5  immunodeficiency syndrome\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find articles enriched for the words corresponding to the\n",
    "# top 5 diseases of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "78e0aa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find keywords for each of the selected diseases\n",
    "keywords_by_disease = {\n",
    "    'breast cancer': [],\n",
    "    'cardiovascular disease': [],\n",
    "    'neurological disease': [],\n",
    "    'blood cancer': [],\n",
    "    'lung cancer': []\n",
    "}\n",
    "for disease in keywords_by_disease.keys():\n",
    "    keywords_by_disease[disease] = list(disease_categories.loc[disease_categories['categorization'] == disease]['word'])\n",
    "\n",
    "# mark appearance of keywords for each article\n",
    "for article, [entities, origin] in raw_combined_data.items():\n",
    "    for disease, keywords in keywords_by_disease.items():\n",
    "        entities[f'is_{disease}_keyword'] = entities.apply(lambda row : 1 if row['normalized word'] in keywords else 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d81784c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_articles = 5 # number of articles per disease category\n",
    "articles_by_disease = {\n",
    "    'breast cancer': [],\n",
    "    'cardiovascular disease': [],\n",
    "    'neurological disease': [],\n",
    "    'blood cancer': [],\n",
    "    'lung cancer': []\n",
    "}\n",
    "\n",
    "# select n_articles number of articles most enriched for keywords for each disease category\n",
    "for disease in keywords_by_disease.keys():\n",
    "    articles_by_keyword_freqs = {}\n",
    "    for article, [entities, origin] in raw_combined_data.items():\n",
    "        articles_by_keyword_freqs[article] = sum(entities[f'is_{disease}_keyword'])\n",
    "    articles_by_disease[disease] = list(sorted(articles_by_keyword_freqs.items(), key=lambda i: i[1], reverse=True)[:n_articles])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "36f4d74f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'breast cancer': [('10.1016/j.jcpa.2012.01.021', 13),\n",
       "  ('10.1016/j.bbagrm.2019.03.002', 12),\n",
       "  ('10.1016/j.bbrc.2019.02.088', 12),\n",
       "  ('10.1016/j.gene.2022.146463', 10),\n",
       "  ('10.1016/j.freeradbiomed.2016.08.031', 9)],\n",
       " 'cardiovascular disease': [('10.1016/j.tcm.2015.08.006', 18),\n",
       "  ('10.1007/s10741-015-9483-x', 10),\n",
       "  ('10.1038/s41371-019-0218-7', 9),\n",
       "  ('10.1016/j.bbadis.2020.165836', 8),\n",
       "  ('10.1016/j.neuint.2019.03.004', 7)],\n",
       " 'neurological disease': [('10.1007/s00401-017-1732-8', 13),\n",
       "  ('10.1016/j.nbd.2014.11.023', 9),\n",
       "  ('10.1016/j.biopha.2018.01.110', 8),\n",
       "  ('10.1007/s10571-013-0012-y', 8),\n",
       "  ('10.1007/s11060-018-03018-6', 8)],\n",
       " 'blood cancer': [('10.1038/leu.2010.276', 16),\n",
       "  ('10.1038/leu.2012.86', 15),\n",
       "  ('10.1016/j.leukres.2005.05.010', 8),\n",
       "  ('10.1016/j.mehy.2013.04.021', 8),\n",
       "  ('10.1007/s00018-018-2895-8', 8)],\n",
       " 'lung cancer': [('10.1053/j.seminoncol.2005.07.007', 9),\n",
       "  ('10.1007/s10555-015-9563-3', 9),\n",
       "  ('10.1016/j.jss.2003.11.024', 6),\n",
       "  ('10.3816/CLC.2008.n.053', 5),\n",
       "  ('10.1038/sj.onc.1209068', 5)]}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles_by_disease"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
